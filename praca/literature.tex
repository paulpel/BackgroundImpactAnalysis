\chapter*{Przegląd literatury}

W ramach niniejszego rozdziału przedstawiony zostanie przegląd literatury dotyczący 
kluczowych zagadnień związanych z klasyfikacją obrazów, segmentacją obrazów oraz wpływem 
tła na wyniki klasyfikacji. Celem tego przeglądu jest zrozumienie dotychczasowych badań i rozwiązań, 
które mogą być istotne dla realizacji niniejszej pracy. Omówione zostaną zarówno klasyczne, jak i 
nowoczesne podejścia do tych problemów, ze szczególnym uwzględnieniem zaawansowanych modeli głębokiego 
uczenia, takich jak ResNet i ConvNeXt. Przegląd ten pozwoli na identyfikację luk w istniejącej 
literaturze oraz wskazanie potencjalnych kierunków dalszych badań.

\section*{Zakres przeglądu literatury}

\begin{enumerate}
    \item \textbf{Klasyfikacja obrazów:}
    \begin{itemize}
        \item Historia i ewolucja metod klasyfikacji obrazów.
        \item Przegląd tradycyjnych technik, takich jak SVM i K-NN, oraz ich ograniczeń.
        \item Wprowadzenie do modeli głębokiego uczenia, w tym sieci neuronowych i 
        konwolucyjnych sieci neuronowych (CNN).
    \end{itemize}
    \item \textbf{Modele głębokiego uczenia:}
    \begin{itemize}
        \item Szczegółowy przegląd architektur ResNet i ConvNeXt.
        \item Analiza wyników i wydajności tych modeli w różnych zadaniach klasyfikacji.
        \item Porównanie ResNet i ConvNeXt z innymi popularnymi modelami, takimi jak VGG i Inception.
    \end{itemize}
    \item \textbf{Segmentacja obrazów:}
    \begin{itemize}
        \item Przegląd technik segmentacji obrazów, w tym tradycyjnych metod oraz 
        podejść opartych na głębokim uczeniu.
        \item Modele segmentacyjne takie jak U-Net, Mask R-CNN i inne.
        \item Zastosowania segmentacji obrazów w różnych dziedzinach.
    \end{itemize}
    \item \textbf{Wpływ tła na klasyfikację obrazów:}
    \begin{itemize}
        \item Przegląd badań dotyczących wpływu tła na wyniki klasyfikacji obrazów.
    \end{itemize}
    \item \textbf{Metryki oceny jakości modeli:}
    \begin{itemize}
        \item Omówienie metryk używanych do oceny jakości modeli klasyfikacyjnych i segmentacyjnych.
        \item Dokładność, precyzja, recall, F1-score i inne miary.
    \end{itemize}
\end{enumerate}


\section*{Klasyfikacja obrazów}

Klasyfikacja obrazów to jedno z fundamentalnych zadań w dziedzinie przetwarzania obrazów i 
komputerowego rozpoznawania wzorców. Proces ten polega na przypisaniu każdemu obrazowi jednej 
lub więcej etykiet z predefiniowanego zbioru klas. Technologia ta znalazła zastosowanie w wielu 
dziedzinach, takich jak medycyna, bezpieczeństwo, rolnictwo, czy automatyka przemysłowa. W ramach 
tego przeglądu omówione zostaną tradycyjne metody klasyfikacji obrazów, ewolucja podejść z 
wykorzystaniem głębokiego uczenia oraz zaawansowane architektury sieci neuronowych. \cite{class_trad_deep} \cite{class_trad_deep2}

\subsection*{Tradycyjne metody klasyfikacji obrazów}

W początkowych etapach rozwoju klasyfikacji obrazów stosowano głównie techniki oparte
na ręcznie wyodrębnianych cechach oraz klasyfikatorach statystycznych. Do najbardziej
popularnych metod należały:

\begin{itemize}
    \item \textbf{Support Vector Machines (SVM):}\cite{svm_survey}Technika ta polega na znajdowaniu hiperpowierzchni, 
    która najlepiej rozdziela klasy w przestrzeni cech. SVM były szeroko stosowane w klasyfikacji 
    obrazów dzięki swojej skuteczności w radzeniu sobie z nieliniowymi danymi \cite{linear_nonlinear} poprzez zastosowanie 
    funkcji jądrowych. \cite{kernel}  
    \item \textbf{K-Nearest Neighbors (K-NN):} Algorytm ten klasyfikuje nowy przykład na podstawie 
    większości głosów najbliższych sąsiadów w przestrzeni cech. Pomimo swojej prostoty, K-NN często 
    wymaga dużych zasobów obliczeniowych i pamięciowych, szczególnie przy dużych zbiorach danych. \cite{knn}
    \item \textbf{Metody oparte na histogramach cech:} Techniki takie jak Histogram of Oriented 
    Gradients (HOG)\cite{hog} czy Scale-Invariant Feature Transform (SIFT) \cite{sift} były używane do ekstrakcji cech z 
    obrazów, które następnie były klasyfikowane za pomocą modeli takich jak SVM czy K-NN. \cite{svm_sift}
\end{itemize}

\subsection*{Ewolucja podejść z wykorzystaniem głębokiego uczenia}

Wraz z rozwojem technologii głębokiego uczenia, tradycyjne metody zaczęły ustępować 
miejsca konwolucyjnym sieciom neuronowym (CNN), które zrewolucjonizowały klasyfikację obrazów. 
CNN automatycznie uczą się cech bez potrzeby ręcznego ich wyodrębniania, co pozwala na osiąganie 
znacznie lepszych wyników. \cite{cnn_overview}

\begin{itemize}
    \item \textbf{Convolutional Neural Networks (CNN):} CNN składają się z warstw konwolucyjnych, 
    poolingowych i w pełni połączonych, które są trenowane w sposób end-to-end na surowych danych 
    obrazowych. Pionierskie prace takie jak AlexNet, VGG i GoogLeNet zapoczątkowały erę głębokiego 
    uczenia w klasyfikacji obrazów, osiągając znacznie lepsze wyniki niż tradycyjne metody. \cite{cnn_survey}
    \item \textbf{Residual Networks (ResNet):}  Wprowadzenie ResNet w 2015 roku było przełomem 
    w dziedzinie głębokiego uczenia. ResNet wprowadza pojęcie "residual learning" z wykorzystaniem 
    warstw skrótowych (skip connections), co pozwala na trenowanie bardzo głębokich sieci z tysiącami 
    warstw bez problemu zanikania gradientu. \cite{resnet} \cite{residual}
    \item \textbf{Transformers} Chociaż pierwotnie zaprojektowane do przetwarzania języka naturalnego, 
    architektury oparte na transformerach, takie jak Vision Transformer (ViT), zaczęły być stosowane 
    również w klasyfikacji obrazów. Transformery wykorzystują mechanizm uwagi (attention mechanism), 
    co pozwala na modelowanie globalnych zależności w danych. \cite{vit_survey}
\end{itemize}

\subsection*{Zaawansowane architektury sieci neuronowych}

Obecnie w klasyfikacji obrazów stosuje się wiele zaawansowanych architektur, 
które rozwijają i ulepszają wcześniejsze koncepcje: \cite{deep3} \cite{soa}

\begin{itemize}
    \item \textbf{ConvNeXt:} Jest to nowoczesna architektura CNN, która łączy zalety tradycyjnych 
    konwolucyjnych sieci neuronowych z nowymi pomysłami pochodzącymi od transformerów. 
    ConvNeXt wykorzystuje bardziej złożone operacje konwolucyjne oraz zaawansowane techniki 
    normalizacji, co pozwala na osiąganie znakomitych wyników w różnych zadaniach klasyfikacji. \cite{convnext}
    \item \textbf{EfficientNet:}  EfficientNet wprowadza skalowanie sieci, które jednocześnie 
    zwiększa głębokość, szerokość i rozdzielczość sieci w zrównoważony sposób. Podejście to 
    pozwala na tworzenie modeli, które są bardziej efektywne obliczeniowo i mogą osiągać wyższą 
    dokładność przy mniejszym zużyciu zasobów. \cite{Efficientnet}
\end{itemize}

\subsection*{Podsumowanie}
Przegląd literatury dotyczącej klasyfikacji obrazów pokazuje, jak ewoluowały metody od 
tradycyjnych technik opartych na ręcznie wyodrębnianych cechach do zaawansowanych modeli 
głębokiego uczenia. Nowoczesne architektury, takie jak ResNet i ConvNeXt, oferują znakomite 
wyniki i są obecnie standardem w wielu zastosowaniach przemysłowych i naukowych. Zrozumienie 
tych technologii i ich rozwoju jest kluczowe dla dalszych badań i optymalizacji modeli 
klasyfikacyjnych, zwłaszcza w kontekście analizy wpływu tła na wyniki klasyfikacji obrazów.

\section*{Segmentacja obrazów}

Segmentacja obrazów to kluczowy proces w dziedzinie przetwarzania obrazów,
polegający na podziale obrazu na znaczące fragmenty, które mogą reprezentować 
różne obiekty lub regiony. Techniki segmentacji są szeroko stosowane w wielu dziedzinach,
takich jak medycyna, robotyka, analiza wideo i rozpoznawanie obiektów. W ramach tego przeglądu 
literatury omówione zostaną tradycyjne metody segmentacji, nowoczesne podejścia wykorzystujące 
głębokie uczenie oraz ich zastosowania w różnych kontekstach. \cite{seg_tec}

\subsection*{Tradycyjne metody segmentacji obrazów}

W początkowych etapach rozwoju segmentacji obrazów stosowano głównie metody oparte na analizie 
cech niskiego poziomu, takich jak kolor, tekstura i krawędzie. Do najpopularniejszych technik należały:

\begin{enumerate}
    \item \textbf{Segmentacja oparta na progach:} Technika ta polega na podziale obrazu na regiony 
    na podstawie wartości pikseli. Progi mogą być ustalane globalnie dla całego obrazu lub lokalnie 
    dla poszczególnych regionów. Chociaż metoda ta jest prosta, jej skuteczność zależy od 
    odpowiedniego doboru progów i jest ograniczona w przypadkach obrazów z złożonymi teksturami i 
    oświetleniem. \cite{seg_tres}
    \item \textbf{Segmentacja oparta na krawędziach:} Metody te wykorzystują detekcję krawędzi 
    do identyfikacji granic między różnymi obiektami w obrazie. Algorytmy takie jak Canny edge 
    detector i Sobel operator są powszechnie stosowane do wykrywania krawędzi, które następnie 
    służą do segmentacji obrazu. \cite{edge_seg}
\end{enumerate}

\subsection*{Nowoczesne podejścia wykorzystujące głębokie uczenie}

Rozwój głębokiego uczenia wprowadził znaczące innowacje w dziedzinie segmentacji obrazów, 
zwłaszcza dzięki zastosowaniu konwolucyjnych sieci neuronowych (CNN). Modele te automatycznie 
uczą się reprezentacji cech z obrazów, co prowadzi do znacznie lepszej dokładności segmentacji w 
porównaniu do tradycyjnych metod. \cite{deep_seg}

\begin{enumerate}
    \item \textbf{Fully Convolutional Networks (FCN):} Wprowadzone przez Longa et al. w 2015 roku, 
    FCN przekształcają tradycyjne CNN, zastępując w pełni połączone warstwy konwolucyjnymi, co 
    pozwala na generowanie map segmentacji o tej samej rozdzielczości co wejściowy obraz. 
    FCN były pierwszym krokiem w kierunku end-to-end segmentacji obrazów. \cite{fcc}
    \item \textbf{U-Net:} Zaproponowany przez Ronnebergera et al. w 2015 roku, U-Net stał się 
    standardem w dziedzinie segmentacji medycznych obrazów. Architektura U-Net składa się z 
    symetrycznej struktury, która łączy warstwy składające się z konwolucji i upsamplingu, co 
    umożliwia precyzyjne segmentowanie obiektów. U-Net wyróżnia się również dzięki połączeniom 
    między warstwami, które przekazują szczegółowe informacje z warstw niskiego poziomu do warstw 
    wyższego poziomu, poprawiając dokładność segmentacji. \cite{unet}
    \item \textbf{Mask R-CNN:} Rozwinięcie Faster R-CNN, Mask R-CNN rozszerza funkcjonalność detekcji obiektów o możliwość segmentacji. 
    Model ten dodaje gałąź segmentacyjną do istniejącej architektury detekcji obiektów, 
    umożliwiając precyzyjne maskowanie wykrytych obiektów. Mask R-CNN osiągnął znakomite 
    wyniki w wielu zadaniach segmentacji i detekcji obiektów. \cite{mask}
    \item \textbf{DeepLab:} Rodzina modeli DeepLab, opracowana przez zespół Google, wykorzystuje 
    różne techniki do poprawy segmentacji, takie jak atrous convolutions (dylatowane konwolucje) i 
    Conditional Random Fields (CRFs). DeepLabv3+, najnowsza wersja tej serii, łączy atrous 
    convolutions z modulem spatial pyramid pooling, co pozwala na uchwycenie kontekstowych 
    informacji na różnych skalach. \cite{deeplab}
\end{enumerate}

\subsection*{Zastosowania segmentacji obrazów}

Techniki segmentacji obrazów znalazły szerokie zastosowanie w różnych dziedzinach. 
W medycynie segmentacja obrazów jest kluczowa w diagnostyce i planowaniu leczenia, 
pozwalając na precyzyjne wyodrębnienie struktur anatomicznych i patologicznych z obrazów MRI i CT. 
W robotyce segmentacja pomaga w nawigacji i manipulacji obiektami, umożliwiając robotom 
zrozumienie i interakcję z otoczeniem. W analizie wideo segmentacja jest używana do śledzenia 
obiektów i rozpoznawania scen, co ma zastosowanie w monitoringu i automatycznym nadzorze.

\subsection*{Podsumowanie}

Przegląd literatury dotyczącej segmentacji obrazów ukazuje, jak ewoluowały techniki od tradycyjnych 
metod opartych na analizie cech niskiego poziomu do zaawansowanych podejść wykorzystujących głębokie 
uczenie. Nowoczesne architektury, takie jak FCN, U-Net, Mask R-CNN i DeepLab, oferują znakomite wyniki 
i są szeroko stosowane w różnych dziedzinach. Zrozumienie tych technik i ich zastosowań jest kluczowe 
dla dalszych badań i optymalizacji procesów segmentacji, zwłaszcza w kontekście analizy wpływu tła na 
wyniki klasyfikacji obrazów.


\section*{Wpływ tła na klasyfikację obrazów}

Badania nad wpływem tła na klasyfikację obrazów konwolucyjnymi sieciami neuronowymi (CNN) wykazały, 
że tło może znacząco wpływać na skuteczność i proces uczenia tych modeli. Przeprowadzone zostały badania nad klasyfikacją binarną osób, gdzie pokazali, że usunięcie zbędnego 
tła z obrazów może znacząco poprawić proces uczenia sieci neuronowych, szczególnie w przypadkach 
ograniczonej liczby próbek treningowych. Eksperymenty wykazały, że sieci trenowane na obrazach bez 
tła były w stanie szybciej rozpocząć proces konwergencji, podczas gdy sieci trenowane na pełnych 
brazach miały z tym problemy, szczególnie gdy tło stanowiło ponad 50\% obrazu. Wyniki te sugerują, 
że usunięcie tła może znacznie zwiększyć efektywność procesu uczenia w przypadkach, gdy stosunek 
sygnału do szumu jest niski. \cite{bg_1}

W kolejnym badaniu autorzy analizowali 32 różne architektury sieci neuronowych, od małych sieci do 
dużych modeli trenowanych na miliardzie obrazów, aby zbadać wpływ cech tła na dokładność klasyfikacji. 
Badania te wykazały, że wraz ze wzrostem mocy obliczeniowej sieci, tendencja do wykorzystywania 
informacji z tła również wzrasta. W eksperymentach, w których maskowano treść pierwszoplanową i 
pozostawiano jedynie tło, sieci nadal były w stanie dokonywać poprawnych predykcji w wielu 
przypadkach. Ponadto, zmiana tła na jednorodne lub teksturalne prowadziła do znacznego spadku 
dokładności, co podkreśla, że obecne sieci neuronowe silnie polegają na informacjach z tła do 
dokonywania klasyfikacji. \cite{bg_2}

W badaniach dotyczących klasyfikacji obrazów liści roślin, wykorzystano kombinację segmentacji 
krawędziowej, morfologicznej oraz odejmowania tła, co pozwoliło na poprawę dokładności klasyfikacji 
w przypadku zdjęć z niejednorodnym tłem. W eksperymentach zastosowano sieci DenseNet121, 
InceptionV3 i inne, osiągając dokładność do 98.7\% na czystych zbiorach danych. Segmentacja pomogła 
w izolacji liści w pierwszym planie, usuwając niepożądane elementy takie jak inne części roślin, 
gleba czy części ciała ludzi, co znacznie poprawiło precyzję klasyfikacji. \cite{bg_3} 


Badanie dotyczące rozumienia mody w kontekście wizji komputerowej wykazuje, że usunięcie tła z obrazów modowych może poprawić jakość danych i zwiększyć wydajność modeli. W eksperymentach z zastosowaniem techniki Salient Object 
Detection stwierdzono, że obrazy bez tła mogą poprawić dokładność modeli o nawet 5\% w klasyfikacji na zestawie danych FashionStyle14, szczególnie w przypadku prostych i płytkich sieci, które nie są podatne na przeuczenie. 
Jednakże, w przypadku głębokich sieci neuronowych, usunięcie tła może być niekorzystne ze względu na niekompatybilność z technikami regularizacji, takimi jak normalizacja wsadowa, inicjalizacja pretrenowana i augmentacje danych, co 
zwiększa ryzyko przeuczenia. \cite{bg_5}


Podobnie, w badaniach nad klasyfikacją obrazów w rolnictwie, autorzy pokazali, 
że wykorzystanie segmentacji i odejmowania tła może znacząco poprawić dokładność klasyfikacji 
obrazów roślin. W eksperymentach użyto technik takich jak segmentacja krawędziowa, morfologiczna i 
odejmowanie tła, co pozwoliło na izolację liści roślin w pierwszym planie. Zastosowanie tych 
technik w połączeniu z sieciami neuronowymi, takimi jak DenseNet121 i InceptionV3, pozwoliło na 
osiągnięcie bardzo wysokiej dokładności klasyfikacji nawet w przypadkach, gdy obrazy były zrobione 
w niejednorodnym tle. \cite{bg_4}


Wszystkie te badania podkreślają znaczenie manipulacji tłem w procesie trenowania i klasyfikacji 
obrazów przy użyciu sieci neuronowych. Usunięcie lub manipulacja tłem może nie tylko poprawić 
dokładność, ale również pomóc sieciom w lepszym zrozumieniu i generalizacji cech istotnych dla 
danego zadania. W przyszłości badania te mogą prowadzić do opracowania bardziej zaawansowanych 
technik segmentacji i manipulacji tłem, które będą kluczowe dla dalszego rozwoju i optymalizacji 
sieci neuronowych w różnych dziedzinach zastosowań, takich jak rolnictwo, medycyna, czy systemy 
monitoringu.

\subsection*{Wyzwania i przyszłe kierunki badań}

Mimo znaczących postępów w zakresie usuwania i modyfikacji tła, istnieje wiele wyzwań, które wciąż 
wymagają dalszych badań. Jednym z głównych problemów jest radzenie sobie z dynamicznymi i zmiennymi 
warunkami tła, takimi jak zmiany oświetlenia, ruch obiektów i różnorodność scen. Ponadto, badania nad 
wpływem tła na klasyfikację obrazów mogą prowadzić do opracowania bardziej odpornych modeli, które 
lepiej radzą sobie z zakłóceniami tła.

Przyszłe badania mogą również koncentrować się na integracji technik usuwania i modyfikacji tła z 
innymi metodami przetwarzania obrazów, takimi jak detekcja obiektów i analiza scen. Opracowanie 
bardziej zaawansowanych algorytmów, które będą w stanie lepiej modelować złożone sceny i dynamiczne 
tła, może przyczynić się do dalszej poprawy wyników klasyfikacji obrazów.

\subsection*{Podsumowanie}

Przegląd literatury dotyczącej wpływu tła na klasyfikację obrazów ukazuje, jak istotny jest to 
aspekt w dziedzinie przetwarzania obrazów i głębokiego uczenia. Techniki usuwania i modyfikacji 
tła mogą znacząco poprawić dokładność klasyfikacji, jednak nadal istnieje wiele wyzwań, które 
wymagają dalszych badań. Zrozumienie wpływu tła na wyniki klasyfikacji oraz opracowanie skutecznych 
metod radzenia sobie z tym problemem jest kluczowe dla rozwoju bardziej niezawodnych i precyzyjnych 
systemów klasyfikacyjnych.

\section*{Metryki oceny jakości modeli}

Ocena jakości modeli klasyfikacyjnych i segmentacyjnych jest kluczowym elementem każdego badania w 
dziedzinie przetwarzania obrazów i głębokiego uczenia. Wybór odpowiednich metryk pozwala na obiektywne 
porównanie różnych modeli oraz identyfikację ich mocnych i słabych stron. W ramach tego przeglądu 
literatury omówione zostaną najważniejsze metryki stosowane do oceny jakości modeli, w tym dokładność, 
precyzja, recall, F1-score oraz inne zaawansowane miary. \cite{metrtics}

\subsection*{Dokładność (Accuracy)}

Dokładność jest jedną z najbardziej intuicyjnych metryk stosowanych do oceny modeli klasyfikacyjnych. 
Jest to stosunek liczby poprawnie sklasyfikowanych przykładów do całkowitej liczby przykładów. 
Chociaż dokładność jest łatwa do zrozumienia i szeroko stosowana, może być myląca w przypadku 
niezrównoważonych zbiorów danych, gdzie liczba przykładów jednej klasy znacznie przewyższa liczbę 
przykładów innych klas. W takich sytuacjach dokładność może być wysoka, nawet jeśli model nie radzi 
sobie dobrze z rzadkimi klasami.

\subsection*{Precyzja (Precision)}

Precyzja, znana również jako dodatnia wartość predykcyjna, to stosunek liczby prawdziwie pozytywnych 
przykładów do liczby wszystkich przykładów sklasyfikowanych jako pozytywne. W kontekście klasyfikacji 
binarnej precyzja mierzy, jak wiele z przykładów sklasyfikowanych jako pozytywne faktycznie należy do 
klasy pozytywnej. Wysoka precyzja oznacza, że model rzadko klasyfikuje negatywne przykłady jako 
pozytywne, co jest szczególnie ważne w aplikacjach, gdzie fałszywe alarmy są kosztowne lub niepożądane.

\subsection*{Czułość (Recall)}

Recall, znany również jako czułość lub true positive rate, to stosunek liczby prawdziwie pozytywnych 
przykładów do liczby wszystkich rzeczywistych pozytywnych przykładów. Recall mierzy zdolność modelu 
do wykrywania wszystkich pozytywnych przykładów w zbiorze danych. Wysoki recall oznacza, że model 
rzadko przeocza pozytywne przykłady, co jest ważne w aplikacjach, gdzie wykrycie wszystkich 
pozytywnych przypadków jest kluczowe, na przykład w diagnostyce medycznej.

\subsection*{F1-Score}

F1-score to harmoniczna średnia precyzji i recall, która stanowi kompromis między tymi dwiema miarami. 
Jest szczególnie użyteczna w przypadkach, gdy istotne jest jednoczesne zminimalizowanie liczby 
fałszywie pozytywnych i fałszywie negatywnych klasyfikacji. F1-score jest bardziej informatywny niż 
dokładność w kontekście niezrównoważonych zbiorów danych, ponieważ uwzględnia zarówno precyzję, 
jak i recall.

\subsection*{Inne zaawansowane miary}

Oprócz podstawowych metryk, istnieje wiele zaawansowanych miar stosowanych do oceny jakości modeli, 
w tym:

\begin{itemize}
    \item \textbf{ROC AUC (Area Under the Receiver Operating Characteristic Curve): }
    ROC AUC jest miarą, która ocenia zdolność modelu do rozróżniania między klasami na podstawie 
    analizy krzywej ROC. Wartość AUC bliska 1 oznacza, że model ma doskonałą zdolność rozróżniania 
    między pozytywnymi a negatywnymi przykładami.
    \item \textbf{AP (Average Precision):} Średnia precyzja to miara, która ocenia średnią precyzję 
    przy różnych wartościach recall. Jest często stosowana w zadaniach detekcji obiektów i 
    segmentacji, gdzie istotne jest ocenienie jakości predykcji na różnych poziomach czułości.
    \item \textbf{IoU (Intersection over Union):} IoU jest miarą stosowaną w segmentacji obrazów, 
    która mierzy stosunek pola wspólnego (intersection) między przewidywaną maską segmentacyjną a 
    rzeczywistą maską do pola sumy (union) tych masek. Wysoki IoU oznacza, że przewidywana maska 
    dobrze pokrywa się z rzeczywistą maską obiektu.
\end{itemize}

\subsection*{Zastosowanie metryk w praktyce}

W praktyce wybór odpowiednich metryk zależy od specyfiki zadania i rodzaju danych. Na przykład, 
w diagnostyce medycznej ważne jest używanie recall i F1-score, aby zapewnić, że wszystkie przypadki 
choroby są wykrywane, a liczba fałszywie negatywnych wyników jest minimalna. W systemach monitoringu 
i detekcji obiektów, metryki takie jak AP i IoU są kluczowe do oceny precyzji i dokładności 
lokalizacji obiektów.
